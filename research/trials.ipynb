{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import sys\n",
    "%cd  ..\n",
    "%cd yolov7/\n",
    "os.getcwd()\n",
    "# !pip install -r requirements.txt -q           #use this for the if running this file for the first time\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"video_path = '../test_videos/v1.mp4'\n",
    "!python ./yolov7/detect.py --weights ./best.pt --conf 0.25 --img-size 640 --source ./test_videos/v1.mp4\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import models\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "# Assuming you have a detect function defined somewhere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate bounding box coordinates from YOLO output\n",
    "\n",
    "def get_BBOX_coordinates(image_width, image_height, x_center, y_center, width, height):\n",
    "    # Calculate pixel coordinates\n",
    "    x_center_pixel = x_center * image_width\n",
    "    y_center_pixel = y_center * image_height\n",
    "    half_width = (width * image_width) / 2\n",
    "    half_height = (height * image_height) / 2\n",
    "\n",
    "    # Calculate top-left and bottom-right coordinates\n",
    "    x_min = int(x_center_pixel - half_width)\n",
    "    y_min = int(y_center_pixel - half_height)\n",
    "    x_max = int(x_center_pixel + half_width)\n",
    "    y_max = int(y_center_pixel + half_height)\n",
    "\n",
    "    return x_min, y_min, x_max, y_max\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from models.experimental import attempt_load\n",
    "from utils.general import non_max_suppression, scale_coords\n",
    "#parent_dir = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "#sys.path.append(parent_dir)\n",
    "#from sounds import play_alert_sound\n",
    "# Path to your custom weights\n",
    "weights_path = '../best.pt'\n",
    "\n",
    "# Load the YOLOv7 model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = attempt_load(weights_path, map_location=device)\n",
    "model.eval()\n",
    "\n",
    "# Define the video path\n",
    "video_path = '../test_videos/v1.mp4'\n",
    "\n",
    "# Load the video file\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "if not cap.isOpened():\n",
    "    print(f\"Error: Cannot open video file {video_path}\")\n",
    "    exit()\n",
    "\n",
    "# Define polygon coordinates\n",
    "polygon_points = np.array([(380, 100), (380, 590), (480, 100), (480, 590)], np.int32)\n",
    "\n",
    "# Loop through the video frames\n",
    "while cap.isOpened():\n",
    "    success, frame = cap.read()\n",
    "    if not success:\n",
    "        print(\"Reached the end of the video or failed to read frame.\")\n",
    "        break\n",
    "\n",
    "    # Pre-process the frame\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(frame_rgb, (640, 480))\n",
    "    img = img.transpose(2, 0, 1)\n",
    "    img = np.ascontiguousarray(img)\n",
    "    img_tensor = torch.from_numpy(img).to(device).float() / 255.0\n",
    "    if img_tensor.ndimension() == 3:\n",
    "        img_tensor = img_tensor.unsqueeze(0)\n",
    "\n",
    "    # Run inference\n",
    "    with torch.no_grad():\n",
    "        pred = model(img_tensor)[0]\n",
    "\n",
    "    # Apply NMS\n",
    "    pred = non_max_suppression(pred, 0.5, 0.45, classes=None, agnostic=False)\n",
    "\n",
    "    # Check bounding boxes against the polygon\n",
    "    for det in pred:\n",
    "        if det is not None and len(det):\n",
    "            det[:, :4] = scale_coords(img_tensor.shape[2:], det[:, :4], frame.shape).round()\n",
    "\n",
    "            for *xyxy, conf, cls in det:\n",
    "                x1, y1, x2, y2 = map(int, xyxy)\n",
    "\n",
    "                # Check corners of the bounding box\n",
    "                corners = [(x1, y1), (x2, y1), (x1, y2), (x2, y2)]\n",
    "                inside_polygon = any(cv2.pointPolygonTest(polygon_points, corner, False) >= 0 for corner in corners)\n",
    "\n",
    "                if inside_polygon:\n",
    "                    cv2.putText(frame, \"Alert!\", (x1, y1 - 10),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "    # Display the annotated frame\n",
    "    cv2.imshow('Annotated Video', frame)\n",
    "\n",
    "    # Break the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remember always stay in yolov7 dir and not in its parent dir other wise no modula named models error will pop "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
